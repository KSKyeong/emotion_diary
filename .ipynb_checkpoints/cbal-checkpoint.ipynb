{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "#--------#\n",
    "\n",
    "from utils.datasets import get_labels\n",
    "from utils.inference import detect_faces\n",
    "from utils.inference import draw_text\n",
    "from utils.inference import draw_bounding_box\n",
    "from utils.inference import apply_offsets\n",
    "from utils.inference import load_detection_model\n",
    "from utils.inference import load_image\n",
    "from utils.preprocessor import preprocess_input\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "time.strftime('WIN_%Y%m%d_%H_%M_%S_Pro',time.localtime(time.time()))\n",
    "    \n",
    "    cv2.destroyAllWindows() # 재촬영 시 모두 포맷하고 사진 찍을 준비.\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = capture.read() # 실시간으로 프레임을 받아준다\n",
    "        cv2.imshow(\"VideoFrame\", frame)\n",
    "        if cv2.waitKey(1) > 0: # 아무 키나 입력 할 때까지 실시간 카메라 보여줌\n",
    "            #키 입력 시 사진 바로 captured_img에 저장됨\n",
    "            \n",
    "            cv2.imwrite(os.path.join(folder_to_save , 'captured_img.jpg'), frame) # 변수 활용(시간, 위치)\n",
    "            return folder_to_save + '\\captured_img.jpg'\n",
    "            \n",
    "def image_handler(folder_to_save):  # 사진 확인 및 재촬영 의사를 확인한다.\n",
    "    #saved_path = \"\"\n",
    "    while(True):\n",
    "        saved_path = start(folder_to_save) # 아무 키나 눌렀을 때 저장되고, 그 사진의 저장된 경로를 반환 해준다.\n",
    "        img_file = r'C:\\Users\\kyung\\Anaconda3\\images\\captured_img.jpg'  # 변수 활용(시간, 위치)\n",
    "        img = cv2.imread(img_file,cv2.IMREAD_COLOR) \n",
    "        cv2.imshow('captured_image',img) \n",
    "    \n",
    "        key = 12354312345\n",
    "        key = cv2.waitKey(0) & 0xFF \n",
    "        if key == ord('r'): # r키 입력 시 재촬영\n",
    "            #start(path)\n",
    "            key = 1212312313\n",
    "            continue\n",
    "        elif key == ord('s'): # s 입력 시 저장\n",
    "            #cv2.imwrite('copy_images/img1_copy.jpg',img) \n",
    "            return saved_path;\n",
    "        #cv2.destroyAllWindow() # 권한이 없다고 한다.\n",
    "        \n",
    "def check_recoged_img(recoged_img_path): # recognition 함수 작동 후 저장된 얼굴 인식 결과 사진을 잠깐 확인 할 수 있게 해준다.\n",
    "    img = cv2.imread(recoged_img_path,cv2.IMREAD_COLOR) \n",
    "    while(True):\n",
    "        cv2.imshow('captured_image',img) \n",
    "\n",
    "        if cv2.waitKey(1) > 0:\n",
    "            break;\n",
    "\n",
    "\n",
    "            \n",
    "def recognition(f_2_s):\n",
    "    \n",
    "    # parameters for loading data and images\n",
    "    #image_path = path_r\n",
    "    image_path = image_handler(f_2_s)\n",
    "    detection_model_path = '../trained_models/detection_models/haarcascade_frontalface_default.xml'\n",
    "    emotion_model_path = '../trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
    "    emotion_labels = get_labels('fer2013')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # hyper-parameters for bounding boxes shape\n",
    "    emotion_offsets = (20, 40)\n",
    "    emotion_offsets = (0, 0)\n",
    "\n",
    "    # loading models\n",
    "    face_detection = load_detection_model(detection_model_path)\n",
    "    emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "    # getting input model shapes for inference\n",
    "    emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "    # loading images\n",
    "    rgb_image = load_image(image_path, grayscale=False)\n",
    "    gray_image = load_image(image_path, grayscale=True)\n",
    "    gray_image = np.squeeze(gray_image)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "\n",
    "    faces = detect_faces(face_detection, gray_image)\n",
    "    for face_coordinates in faces:\n",
    "\n",
    "        x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "        gray_face = gray_image[y1:y2, x1:x2]\n",
    "\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        gray_face = preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        gray_face = np.expand_dims(gray_face, -1)\n",
    "        emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))\n",
    "        emotion_text = \"\"\n",
    "        emotion_text = emotion_labels[emotion_label_arg]\n",
    "\n",
    "        color = (255, 0, 0) # 감정 정보 글씨 빨간색, 사각형도\n",
    "\n",
    "        draw_bounding_box(face_coordinates, rgb_image, color)\n",
    "        draw_text(face_coordinates, rgb_image, emotion_text, color, 0, -30, 1.5, 2)\n",
    "    #if(emotion_text == \"\"):\n",
    "        #recognition(f_2_s)\n",
    "        \n",
    "    bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite('../images/predicted_test_image.png', bgr_image) # 변수 활용\n",
    "    check_recoged_img('../images/predicted_test_image.png')\n",
    "    # 저장된 사진을 감정 예측 후 predicted_test_image.jpg로 저장\n",
    "   \n",
    "\n",
    "            \n",
    "###################################################################################################################################\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    capture = cv2.VideoCapture(0)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 900)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    folder_to_save = r\"C:\\Users\\kyung\\Pictures\\Camera Roll\"\n",
    "    \n",
    "    #recognition(image_handler(folder_to_save))\n",
    "    recognition(folder_to_save)\n",
    "    \n",
    "    \n",
    "    capture.release() \n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
